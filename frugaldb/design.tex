\section{System Design}\label{sec:SDI}

As modern CPUs could provide more and more powerful computing capacity, the disk-based storage subsystem has more and more obviously become the bottleneck for OLTP applications, because of mechanical characteristics of modern magnetic disk devices. There exists a basic observation that computation resources are always under-utilized heavily in a typical OLTP database system, while memory and disk bandwidth are scarce resources and are usually in strong need. So the key point for satiating the performance SLO of an OLTP application is whether the database server could provide enough memory resources to host its working set in memory. If the database server is only configured with very limited memory resources and could not completely host an application's working set in memory, the database would have to frequently visit disk pages, which would make the database system witness deteriorated overall performance with degraded throughput and increased query latency, and the database server would only be able to satiate a relatively low performance SLO necessitated by the application. If memory resources configured on the database server are abundant enough to host the application's working set in memory, the database might be able to process most database operations efficiently without touching underlying disks, and the database only needs to access disks for database log or dirty page flushing operations, so the database server could satiate much higher performance SLOs for the application. So in this paper we basically assume that CPU is not the bottleneck for our DBaaS system, and the bottleneck results from limited amount of available memory and disk bandwidth resources. In this section, we mainly present details about FrugalDB's design and implementation. Firstly we introduce FrugalDB's architecture, and then present the models we employ to describe tenants' workloads, and finally state details about implementation techniques of FrugalDB.

\subsection{System Architecture}\label{sec:Overview}

As shown in Fig.~\ref{fig:Architecture}, FrugalDB fuses a disk-based database and an in-memory database to process tenants' data serving requests, and other key components include:

~1. \emph{Access Controller}: which dispatches data serving requests according to the optimized tenant/workload assignments, and keeps log records of data serving requests for each tenants.

~2. \emph{Log Analyzer}: which processes tenants' request logs recorded by \emph{Access Controller}, extracts tenants' workload characteristics and generates a workload description for each tenant. All tenants' workload descriptions will be fed to the \emph{Workload Offload Engine}, together with tenants' performance SLOs.

~3. \emph{Performance Monitor}: which monitors system performance by tracking corresponding performance metrics(\emph{e.g.} request throughputs and latencies, etc.), and incurs a workload offloading process when it judges that a workload burst occurs, when monitored performance metrics exceed the predefined thresholds.

~4. \emph{Workload Offload Engine}: which is the core component of FrugalDB used to implement workload offloading while making sure that the whole system could gain the most workload offloading benefit. It consists of three modules: \emph{Offloading Benefit Evaluator}, \emph{Data Offloader} and \emph{Data Reloader}. When offloading workloads, \emph{Offloading Benefit Evaluator} evaluates workload offloading benefits of all active tenants, and compute optimized tenant assignments by combining tenants' workload characteristic descriptions provided by \emph{Log Analyzer}, performance metrics provided by \emph{Performance Monitor} and tenants' SLOs. \emph{Offloading Benefit Evaluator} employs the algorithm, which will be discussed later in Sec..~\ref{sec:PFA}, to find an optimal assignment of all tenants' workloads. Then \emph{Data Offloader} begins to offload into the in-memory database workloads of corresponding tenants from the disk-based database. When the workload burst fades out, \emph{Data Reloader} begins to reload into the disk-based database updated data from the in-memory database, so that corresponding memory resources can be released for subsequent workload offloading.

\begin{figure}[!htb]
\centering
\includegraphics[scale=0.44]{figures-final/Architecture.eps}
\caption{FrugalDB's architecture.}
\label{fig:Architecture}
\end{figure}

\subsection{Workload Models}

In a DBaaS multi-tenant environment, a tenant's workload could consist of three different periods: non-active, low-intensity and high-intensity, and various tenant activeness would be presented in different periods. No data serving requests would be yielded during non-active periods, enormous data serving requests would be yielded during high-intensity periods, while a tenant would only yield a moderate number of data serving requests during low-intensity periods, compared with the tenant's performance SLO. If we assume that time consists of sequences of equal intervals, then we could observe that different tenants present various activeness during the same interval, and a tenant's activeness varies across different intervals, which means a tenant's workload may reside in the high-intensity status in an interval, and then turn to the low-intensity status in the subsequent interval, and vice versa. For massive numbers of small tenants with low overall activeness, most tenants' workloads are normally expected to reside in non-active periods or low-intensity periods during most intervals, and only a trivial number of tenants would generate high-intensity workloads during the same interval, which may catch up with their performance SLOs. In this paper, we only take tenants' requirements on query throughput as the evaluation metric when considering QoS.

The basic assumption we hold about tenants' workloads is that \emph{a tenant follows some predictable and repeatable pattern to generate the tenant's workload}. This assumption is reasonable because a tenant usually needs to execute similar business logics at similar time, and thus the overall workload generated by the tenant would statistically follow some pattern conforming to the tenant's business logics, even if some individual operations of the tenant may seem independent and random with no patterns. Curino et al.~\cite{Workload-Aware} validated that a tenant's past workload behavior is a good predictor of the tenant's future behavior by experiments with real-life workload datasets, Schaffner et al.~\cite{Real-Trace} also revealed that tenants' workloads exhibit obvious load patterns by analyzing realistic tenant workload traces collected in a multi-tenant DBaaS environment, and Elmore et al.~\cite{CTBP} further characterized tenants' behaviors for tenant placement and crisis mitigation in multi-tenant DBMSs, so we have good reasons to expect that a tenant's workload could be predictable and could be generated repeatedly over time.

Based on this basic assumption, we derive two kinds of models to describe tenants' workloads applicable in our targeting problem: the deterministic model and non-deterministic model, and we believe both of these models could be applicable for specific scenarios respectively. One important thing worth noting is that: it is difficult and unnecessary to model tenants' workloads at a too tiny time granularity in our targeting scenario, for example to build a model to depict a tenant's workload generated at an exact second, as tenants' activities may present huge variance at such a tiny time granularity, so we only need to model tenants' workloads at a coarser time granularity. We thus partition continuous time into discretized time intervals, and then model to predict tenants' workloads during different intervals, by analyzing workload traces collected during past similar intervals. As the workload traces usually are composed of separate queries submitted at different time instants, we compute the average throughput during each interval for each tenant, and then leverage these piecewise query throughput to model tenants' workloads, just as shown in Fig.~\ref{fig:PAA}.

\begin{figure}[!htb]
\centering
\includegraphics[scale=0.25]{figures-final/Workload-PAA.eps}
\caption{Workload PAA.}
\label{fig:PAA}
\end{figure}


\subsubsection{Deterministic Workload Model}
In the deterministic model, we expect that a tenant would generate roughly identical workload pressure to the DBaaS system at similar intervals, that is to say, we assume that a tenant's workload would be generated repeatedly in a deterministic fashion, and we could precisely predict the tenant's workload at time $t$ in advance. So we expect that tenants generate their workloads periodically, and there exists a workload period $T$ for each tenant, where the workload period $T$ could be caliberated by hours, days, weeks, or even months, so that we could assume that a tenant would generate similar workload pressures during interval $t$ and intervals $t + n * T$($n=1,2,...$).

\subsubsection{Non-Deterministic Workload Model}

In the non-deterministic model, a tenant's workload would be generated in a non-deterministic fashion, where the workload pressure generated by a tenant during an interval is deemed as a random event. In order to predict a tenant's workload during interval $t$, we model a tenant's workload by statistically computing the distribution of the tenant's historical workload pressures generated at similar past intervals $t - n*T$($n=1,2,...$), where $T$ is deemed as the workload period for defining similar times. As a tenant's workload pressure yielded during an interval is quantified by discrete averaged throughput, we range a tenant's workload pressure into different levels for simplicity consideration, and then model the tenant's workload by statistically computing the distribution of workload pressure levels generated at similar intervals. For example, we could divide a tenant's workload pressures into Low, Middle and High these three levels, and then statistically compute the probabilistic distribution of these three workload pressure levels for each similar interval.

For each tenant, we have to obtain a historical workload trace collected during a long enough duration, so that we could have enough samples to build an accurate probabilistic model for the tenant, otherwise the abstracted probability model would not be able to reflect the actual randomness of a tenant's workload activities. We assume that enough workload traces could be collected by DBaaS service providers and we could employ them to build a realistic probability model.
